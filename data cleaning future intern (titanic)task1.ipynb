{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "777d3aac",
   "metadata": {},
   "source": [
    "# dataset of gender_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ab1c949d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/patha/OneDrive/Desktop/future intern/titanic/gender_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7434a370",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling missing values\n",
    "# Drop rows with any missing values\n",
    "df_cleaned = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f6263e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for numerical columns filing missing value median\n",
    "df_filled = df.fillna(df.median())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09d7d4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Handling outliers by z-score\n",
    "from scipy import stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da411071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes rows where Z-score > 3\n",
    "z_scores = np.abs(stats.zscore(df_cleaned.select_dtypes(include=[np.number])))\n",
    "df_no_outliers = df_cleaned[(z_scores < 3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9e791e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the IQR method for outliers\n",
    "Q1 = df_cleaned.quantile(0.25)\n",
    "Q3 = df_cleaned.quantile(0.75)\n",
    "IQR = Q3 - Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8c1b910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering out rows that fall outside 1.5*IQR\n",
    "df_no_outliers_iqr = df_cleaned[~((df_cleaned < (Q1 - 1.5 * IQR)) |(df_cleaned > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e73ed6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    PassengerId  Survived\n",
       " 0          892         0\n",
       " 1          893         1\n",
       " 2          894         0\n",
       " 3          895         0\n",
       " 4          896         1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Output the cleaned data\n",
    "df_no_outliers_iqr.to_csv('C:/Users/patha/OneDrive/Desktop/future intern/Clean data/cleaned_dataset_gender.csv', index=False)\n",
    "# Return the cleaned dataframe's info and head for review\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c23460",
   "metadata": {},
   "source": [
    "## cleaning dataset test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e018575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\"C:/Users/patha/OneDrive/Desktop/future intern/titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8117081e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing age with median\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8276f227",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filling missing fare with median\n",
    "df['Fare'].fillna(df['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ef80366",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop coloumn\n",
    "df.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7290dce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filling missing value with mode\n",
    "if df['Embarked'].isnull().sum() > 0:\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e6a2f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only numeric columns\n",
    "numeric_columns = df.select_dtypes(include=['number'])\n",
    "# Handling outliers using IQR\n",
    "Q1 = numeric_columns.quantile(0.25)\n",
    "Q3 = numeric_columns.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "# Removing outliers\n",
    "df_cleaned = df[~((numeric_columns < (Q1 - 1.5 * IQR)) | (numeric_columns > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a1b5a2a",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Age'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Flter out rows with Age and Fare outliers\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39m((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m (Q1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m|\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m (Q3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAge\u001b[39m\u001b[38;5;124m'\u001b[39m])))]\n\u001b[0;32m      3\u001b[0m df \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;241m~\u001b[39m((df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m (Q1[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m])) \u001b[38;5;241m|\u001b[39m (df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m (Q3[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1.5\u001b[39m \u001b[38;5;241m*\u001b[39m IQR[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFare\u001b[39m\u001b[38;5;124m'\u001b[39m])))]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   3760\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 3761\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   3762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   3763\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3660\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Age'"
     ]
    }
   ],
   "source": [
    "# Flter out rows with Age and Fare outliers\n",
    "df = df[~((df['Age'] < (Q1['Age'] - 1.5 * IQR['Age'])) | (df['Age'] > (Q3['Age'] + 1.5 * IQR['Age'])))]\n",
    "df = df[~((df['Fare'] < (Q1['Fare'] - 1.5 * IQR['Fare'])) | (df['Fare'] > (Q3['Fare'] + 1.5 * IQR['Fare'])))] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "45ea5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode Sex and Embarked columns using one-hot encoding\n",
    "df = pd.get_dummies(df, columns=['Sex', 'Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e4de1c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any duplicate rows\n",
    "df.drop_duplicates(inplace=True)\n",
    "# Save the cleaned dataset\n",
    "df.to_csv(\"C:/Users/patha/OneDrive/Desktop/future intern/Clean data/cleaned_data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f4c68b77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype\n",
      "---  ------       --------------  -----\n",
      " 0   PassengerId  418 non-null    int64\n",
      " 1   Survived     418 non-null    int64\n",
      "dtypes: int64(2)\n",
      "memory usage: 6.7 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    PassengerId  Survived\n",
       " 0          892         0\n",
       " 1          893         1\n",
       " 2          894         0\n",
       " 3          895         0\n",
       " 4          896         1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Return the cleaned dataframe's info and head for review\n",
    "df.info(), df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3fec37",
   "metadata": {},
   "source": [
    "### Cleaning dataset train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abef0503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "71d33420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "file_path = \"C:/Users/patha/OneDrive/Desktop/future intern/titanic/train.csv\" \n",
    "# Path to your dataset\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3bfaab4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset info:\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "#Display information about the dataset\n",
    "print(\"Dataset info:\\n\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "607c35b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "    PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "# Display the first few rows of the dataset\n",
    "print(\"First few rows of the dataset:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1001e067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9c33aebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values after cleaning:\n",
      " PassengerId    0\n",
      "Survived       0\n",
      "Pclass         0\n",
      "Name           0\n",
      "Sex            0\n",
      "Age            0\n",
      "SibSp          0\n",
      "Parch          0\n",
      "Ticket         0\n",
      "Fare           0\n",
      "Cabin          0\n",
      "Embarked       0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Handle missing values\n",
    "# Drop rows where more than 50% of data is missing\n",
    "df = df.dropna(thresh=df.shape[1]*0.5, axis=0)\n",
    "\n",
    "# Fill missing values for numerical columns with the median\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_columns] = df[numerical_columns].fillna(df[numerical_columns].median())\n",
    "\n",
    "# Fill missing values for categorical columns with the mode\n",
    "categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    df[column].fillna(df[column].mode()[0], inplace=True)\n",
    "    \n",
    "print(\"Missing values after cleaning:\\n\", df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6ad0f4ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after outlier removal:\n",
      "        PassengerId  Survived  Pclass         Age  SibSp  Parch        Fare\n",
      "count   134.000000     134.0   134.0  134.000000  134.0  134.0  134.000000\n",
      "mean    468.537313       0.0     3.0   26.212687    0.0    0.0    7.892715\n",
      "std     265.223063       0.0     0.0    4.628847    0.0    0.0    0.161627\n",
      "min       5.000000       0.0     3.0   14.000000    0.0    0.0    7.495800\n",
      "25%     238.750000       0.0     3.0   22.000000    0.0    0.0    7.775000\n",
      "50%     497.500000       0.0     3.0   28.000000    0.0    0.0    7.895800\n",
      "75%     680.000000       0.0     3.0   28.000000    0.0    0.0    8.050000\n",
      "max     891.000000       0.0     3.0   36.000000    0.0    0.0    8.458300\n"
     ]
    }
   ],
   "source": [
    "#remove outliers based on IQR\n",
    "def remove_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    return df[(df[column] >= lower_bound) & (df[column] <= upper_bound)]\n",
    "\n",
    "# Apply to numerical columns\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df = remove_outliers(df, col)\n",
    "\n",
    "# Apply to numerical columns\n",
    "for col in df.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    df = remove_outliers(df, col)\n",
    "\n",
    "print(\"Data after outlier removal:\\n\", df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "724651c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after encoding categorical variables:\n",
      "     PassengerId  Survived  Pclass   Age  SibSp  Parch    Fare  \\\n",
      "4             5         0       3  35.0      0      0  8.0500   \n",
      "5             6         0       3  28.0      0      0  8.4583   \n",
      "12           13         0       3  20.0      0      0  8.0500   \n",
      "14           15         0       3  14.0      0      0  7.8542   \n",
      "29           30         0       3  28.0      0      0  7.8958   \n",
      "\n",
      "    Name_Alexander, Mr. William  Name_Alhomaki, Mr. Ilmari Rudolf  \\\n",
      "4                         False                             False   \n",
      "5                         False                             False   \n",
      "12                        False                             False   \n",
      "14                        False                             False   \n",
      "29                        False                             False   \n",
      "\n",
      "    Name_Allen, Mr. William Henry  ...  Ticket_STON/O 2. 3101280  \\\n",
      "4                            True  ...                     False   \n",
      "5                           False  ...                     False   \n",
      "12                          False  ...                     False   \n",
      "14                          False  ...                     False   \n",
      "29                          False  ...                     False   \n",
      "\n",
      "    Ticket_STON/O 2. 3101292  Ticket_STON/O 2. 3101293  \\\n",
      "4                      False                     False   \n",
      "5                      False                     False   \n",
      "12                     False                     False   \n",
      "14                     False                     False   \n",
      "29                     False                     False   \n",
      "\n",
      "    Ticket_STON/O 2. 3101294  Ticket_STON/O2. 3101290  Ticket_W./C. 6609  \\\n",
      "4                      False                    False              False   \n",
      "5                      False                    False              False   \n",
      "12                     False                    False              False   \n",
      "14                     False                    False              False   \n",
      "29                     False                    False              False   \n",
      "\n",
      "    Cabin_F G73  Cabin_F38  Embarked_Q  Embarked_S  \n",
      "4         False      False       False        True  \n",
      "5         False      False        True       False  \n",
      "12        False      False       False        True  \n",
      "14        False      False       False        True  \n",
      "29        False      False       False        True  \n",
      "\n",
      "[5 rows x 278 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical variables into indicator variables\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "print(\"Data after encoding categorical variables:\\n\", df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "dd8cf6c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data after scaling:\n",
      "     PassengerId  Survived  Pclass       Age  SibSp  Parch      Fare  \\\n",
      "4     -1.754284       0.0     0.0  1.905504    0.0    0.0  0.976787   \n",
      "5     -1.750500       0.0     0.0  0.387574    0.0    0.0  3.512453   \n",
      "12    -1.724008       0.0     0.0 -1.347203    0.0    0.0  0.976787   \n",
      "14    -1.716439       0.0     0.0 -2.648286    0.0    0.0 -0.239189   \n",
      "29    -1.659670       0.0     0.0  0.387574    0.0    0.0  0.019159   \n",
      "\n",
      "    Name_Alexander, Mr. William  Name_Alhomaki, Mr. Ilmari Rudolf  \\\n",
      "4                         False                             False   \n",
      "5                         False                             False   \n",
      "12                        False                             False   \n",
      "14                        False                             False   \n",
      "29                        False                             False   \n",
      "\n",
      "    Name_Allen, Mr. William Henry  ...  Ticket_STON/O 2. 3101280  \\\n",
      "4                            True  ...                     False   \n",
      "5                           False  ...                     False   \n",
      "12                          False  ...                     False   \n",
      "14                          False  ...                     False   \n",
      "29                          False  ...                     False   \n",
      "\n",
      "    Ticket_STON/O 2. 3101292  Ticket_STON/O 2. 3101293  \\\n",
      "4                      False                     False   \n",
      "5                      False                     False   \n",
      "12                     False                     False   \n",
      "14                     False                     False   \n",
      "29                     False                     False   \n",
      "\n",
      "    Ticket_STON/O 2. 3101294  Ticket_STON/O2. 3101290  Ticket_W./C. 6609  \\\n",
      "4                      False                    False              False   \n",
      "5                      False                    False              False   \n",
      "12                     False                    False              False   \n",
      "14                     False                    False              False   \n",
      "29                     False                    False              False   \n",
      "\n",
      "    Cabin_F G73  Cabin_F38  Embarked_Q  Embarked_S  \n",
      "4         False      False       False        True  \n",
      "5         False      False        True       False  \n",
      "12        False      False       False        True  \n",
      "14        False      False       False        True  \n",
      "29        False      False       False        True  \n",
      "\n",
      "[5 rows x 278 columns]\n"
     ]
    }
   ],
   "source": [
    "# Scaling numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_columns = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "df[numerical_columns] = scaler.fit_transform(df[numerical_columns])\n",
    "print(\"Data after scaling:\\n\", df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "03466a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned dataset saved to: C:/Users/patha/OneDrive/Desktop/future intern/Clean data/cleaned_train.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the cleaned dataset to a new file\n",
    "cleaned_file_path = 'C:/Users/patha/OneDrive/Desktop/future intern/Clean data/cleaned_train.csv'\n",
    "df.to_csv(cleaned_file_path, index=False)\n",
    "print(f\"Cleaned dataset saved to: {cleaned_file_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
